import cv2
import numpy as np
import config
import time
import os

# Import TensorRT libraries an to√†n
try:
    import tensorrt as trt
    import pycuda.driver as cuda
    import pycuda.autoinit
except ImportError:
    print("‚ö†Ô∏è TensorRT/PyCUDA not found. Ensure you are running inside the Docker container.")

class VehicleDetector:
    def __init__(self, model_name='yolov8n', imgsz=config.YOLO_IMGSZ):
        self.imgsz = imgsz
        self.conf_threshold = config.CONF_THRESHOLD
        
        # T·ª± ƒë·ªông t√¨m file model
        engine_path = f"{model_name}.engine"
        onnx_path = f"{model_name}.onnx"
        
        print(f"üîÑ Initializing Detector...")

        if os.path.exists(engine_path):
            print(f"üöÄ Found Optimized Engine: {engine_path}")
            self.model_path = engine_path
            self.backend = 'tensorrt'
            self._init_tensorrt(engine_path)
        elif os.path.exists(onnx_path):
            print(f"‚ö†Ô∏è Engine not found, falling back to ONNX: {onnx_path}")
            self.model_path = onnx_path
            self.backend = 'onnx'
            self._init_onnx(onnx_path)
        else:
            raise FileNotFoundError(f"Could not find {engine_path} or {onnx_path}")

    def _init_onnx(self, model_path):
        import onnxruntime as ort
        print("  -> Loading ONNX Runtime...")
        providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
        opts = ort.SessionOptions()
        opts.log_severity_level = 3
        self.session = ort.InferenceSession(model_path, sess_options=opts, providers=providers)
        self.input_name = self.session.get_inputs()[0].name
        self.output_names = [output.name for output in self.session.get_outputs()]
        print(f"  ‚úì ONNX Loaded. Provider: {self.session.get_providers()[0]}")

    def _init_tensorrt(self, model_path):
        print("  -> Loading TensorRT Engine (v10+ compatible)...")
        try:
            self.trt_logger = trt.Logger(trt.Logger.WARNING)
            runtime = trt.Runtime(self.trt_logger)
            
            with open(model_path, 'rb') as f:
                engine_data = f.read()
            
            self.engine = runtime.deserialize_cuda_engine(engine_data)
            self.context = self.engine.create_execution_context()
            
            self.inputs = []
            self.outputs = []
            self.stream = cuda.Stream() # T·∫°o lu·ªìng x·ª≠ l√Ω GPU
            
            # --- LOGIC X·ª¨ L√ù MEMORY (H·ªñ TR·ª¢ TRT 10.x V√Ä 8.x) ---
            
            # C√°ch x√°c ƒë·ªãnh s·ªë l∆∞·ª£ng tensors t√πy version
            if hasattr(self.engine, 'num_io_tensors'):
                num_bindings = self.engine.num_io_tensors
                is_trt_10 = True
            else:
                num_bindings = self.engine.num_bindings
                is_trt_10 = False

            for i in range(num_bindings):
                if is_trt_10:
                    name = self.engine.get_tensor_name(i)
                    mode = self.engine.get_tensor_mode(name)
                    is_input = (mode == trt.TensorIOMode.INPUT)
                    shape = self.engine.get_tensor_shape(name)
                    # FIX L·ªñI TYPE: B·ªçc v√†o np.dtype
                    dtype = np.dtype(trt.nptype(self.engine.get_tensor_dtype(name)))
                else:
                    name = self.engine.get_binding_name(i)
                    is_input = self.engine.binding_is_input(i)
                    shape = self.engine.get_binding_shape(i)
                    # FIX L·ªñI TYPE
                    dtype = np.dtype(trt.nptype(self.engine.get_binding_dtype(i)))

                # X·ª≠ l√Ω Dynamic Shape (n·∫øu c√≥ -1)
                if -1 in shape:
                    print(f"  ‚ö†Ô∏è Warning: Dynamic shape found {shape}, forcing batch=1")
                    lst = list(shape)
                    if lst[0] == -1: lst[0] = 1
                    shape = tuple(lst)

                # T√≠nh k√≠ch th∆∞·ªõc b·ªô nh·ªõ c·∫ßn c·∫•p ph√°t
                size = trt.volume(shape) * dtype.itemsize
                
                # C·∫•p ph√°t b·ªô nh·ªõ tr√™n GPU
                device_mem = cuda.mem_alloc(size)
                
                # T·∫°o binding dictionary
                binding = {
                    'name': name,
                    'index': i,
                    'device': device_mem, # Pointer GPU
                    'host': None,         # Pointer CPU (s·∫Ω t·∫°o cho output)
                    'shape': shape,
                    'dtype': dtype
                }

                if is_input:
                    self.inputs.append(binding)
                    # TRT 10 b·∫Øt bu·ªôc set address
                    if is_trt_10: self.context.set_tensor_address(name, int(device_mem))
                else:
                    # Output c·∫ßn b·ªô nh·ªõ ƒë·ªám ·ªü CPU (Host) ƒë·ªÉ nh·∫≠n k·∫øt qu·∫£ v·ªÅ
                    binding['host'] = cuda.pagelocked_empty(trt.volume(shape), dtype)
                    self.outputs.append(binding)
                    if is_trt_10: self.context.set_tensor_address(name, int(device_mem))

            print("  ‚úì TensorRT Engine Loaded & Memory Allocated.")
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            raise RuntimeError(f"TensorRT Init Failed: {e}")

    def preprocess(self, frame):
        # Resize v√† chu·∫©n h√≥a ·∫£nh cho YOLO
        img = cv2.resize(frame, (self.imgsz, self.imgsz))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = img.astype(np.float32) / 255.0
        img = np.transpose(img, (2, 0, 1)) # HWC -> CHW
        img = np.expand_dims(img, axis=0)  # Th√™m batch dimension -> (1, 3, 640, 640)
        return np.ascontiguousarray(img)

    def detect(self, frame):
        # 1. Preprocess
        input_tensor = self.preprocess(frame)
        
        # 2. Inference
        if self.backend == 'onnx':
            outputs = self.session.run(self.output_names, {self.input_name: input_tensor})
        
        elif self.backend == 'tensorrt':
            # --- FIX L·ªñI INPUT BUFFER T·∫†I ƒê√ÇY ---
            
            # L·∫•y ƒë·ªãa ch·ªâ b·ªô nh·ªõ GPU c·ªßa input ƒë·∫ßu ti√™n
            input_mem = self.inputs[0]['device']
            
            # Copy d·ªØ li·ªáu t·ª´ CPU (input_tensor) l√™n GPU (input_mem)
            cuda.memcpy_htod_async(input_mem, input_tensor, self.stream)
            
            # Th·ª±c thi m√¥ h√¨nh (Execute)
            self.context.execute_async_v3(stream_handle=self.stream.handle)
            
            # Copy k·∫øt qu·∫£ t·ª´ GPU (device) v·ªÅ CPU (host)
            for out in self.outputs:
                cuda.memcpy_dtoh_async(out['host'], out['device'], self.stream)
            
            # ƒê·ªìng b·ªô h√≥a (Ch·ªù GPU ch·∫°y xong)
            self.stream.synchronize()
            
            # L·∫•y k·∫øt qu·∫£ ra list
            outputs = [out['host'].reshape(out['shape']) for out in self.outputs]

        # 3. Postprocess
        return self.postprocess(outputs, frame.shape[:2])

    def postprocess(self, outputs, frame_shape):
        detections = []
        # Output c·ªßa YOLOv8 th∆∞·ªùng l√† [1, 84, 8400] -> c·∫ßn transpose th√†nh [1, 8400, 84]
        output = outputs[0]
        if output.shape[1] == 84: 
            output = np.transpose(output, (0, 2, 1))
        
        output = output[0] # L·∫•y batch ƒë·∫ßu ti√™n
        
        orig_h, orig_w = frame_shape
        scale_x = orig_w / self.imgsz
        scale_y = orig_h / self.imgsz
        
        # Format output: [x, y, w, h, class_probs...]
        classes_scores = output[:, 4:]
        class_ids = np.argmax(classes_scores, axis=1)
        confidences = np.max(classes_scores, axis=1)
        
        # L·ªçc ng∆∞·ª°ng t·ª± tin (Confidence Threshold)
        mask = (confidences > self.conf_threshold) & (np.isin(class_ids, config.VEHICLE_CLASS_IDS))
        
        filtered_output = output[mask]
        filtered_confidences = confidences[mask]
        filtered_class_ids = class_ids[mask]
        
        for i, detection in enumerate(filtered_output):
            x_center, y_center, width, height = detection[:4]
            
            # Chuy·ªÉn ƒë·ªïi t·ªça ƒë·ªô v·ªÅ ·∫£nh g·ªëc
            x1 = int((x_center - width / 2) * scale_x)
            y1 = int((y_center - height / 2) * scale_y)
            x2 = int((x_center + width / 2) * scale_x)
            y2 = int((y_center + height / 2) * scale_y)
            
            # Clip ƒë·ªÉ kh√¥ng vƒÉng ra ngo√†i khung h√¨nh
            x1 = max(0, min(x1, orig_w))
            y1 = max(0, min(y1, orig_h))
            x2 = max(0, min(x2, orig_w))
            y2 = max(0, min(y2, orig_h))
            
            detections.append(([x1, y1, x2, y2], float(filtered_confidences[i]), int(filtered_class_ids[i])))
        
        return detections